{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maxwelllondon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import nltk\n",
    "import ssl\n",
    "from nltk import ne_chunk\n",
    "\n",
    "print(\"hello\")\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./chatgpt.csv.bz2\").sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>username</th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265567</th>\n",
       "      <td>2023-03-14 18:32:35+00:00</td>\n",
       "      <td>1635710533751173121</td>\n",
       "      <td>OpenAI says itâ€™s already partnered w Duolingo,...</td>\n",
       "      <td>issen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323606</th>\n",
       "      <td>2023-03-22 15:23:10+00:00</td>\n",
       "      <td>1638561968310169605</td>\n",
       "      <td>I gave chat gpt access to my hinge premium acc...</td>\n",
       "      <td>IBDeez</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77999</th>\n",
       "      <td>2023-03-14 21:01:01+00:00</td>\n",
       "      <td>1635747884455849984</td>\n",
       "      <td>Embrace the power of AI in the classroom. ðŸ™Œ \\n...</td>\n",
       "      <td>ISTEofficial</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105848</th>\n",
       "      <td>2023-03-27 06:30:31+00:00</td>\n",
       "      <td>1640239859246804993</td>\n",
       "      <td>Returning to Twitter to see what people are bu...</td>\n",
       "      <td>markozivan0vic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288574</th>\n",
       "      <td>2023-01-05 03:20:47+00:00</td>\n",
       "      <td>1610838694180671488</td>\n",
       "      <td>Don't let fear hold you back from reaching you...</td>\n",
       "      <td>Akamotonft</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date                   id  \\\n",
       "265567  2023-03-14 18:32:35+00:00  1635710533751173121   \n",
       "323606  2023-03-22 15:23:10+00:00  1638561968310169605   \n",
       "77999   2023-03-14 21:01:01+00:00  1635747884455849984   \n",
       "105848  2023-03-27 06:30:31+00:00  1640239859246804993   \n",
       "288574  2023-01-05 03:20:47+00:00  1610838694180671488   \n",
       "\n",
       "                                                  content        username  \\\n",
       "265567  OpenAI says itâ€™s already partnered w Duolingo,...           issen   \n",
       "323606  I gave chat gpt access to my hinge premium acc...          IBDeez   \n",
       "77999   Embrace the power of AI in the classroom. ðŸ™Œ \\n...    ISTEofficial   \n",
       "105848  Returning to Twitter to see what people are bu...  markozivan0vic   \n",
       "288574  Don't let fear hold you back from reaching you...      Akamotonft   \n",
       "\n",
       "        like_count  retweet_count  \n",
       "265567         0.0            0.0  \n",
       "323606         0.0            0.0  \n",
       "77999         14.0            8.0  \n",
       "105848         0.0            0.0  \n",
       "288574        11.0            6.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "date             0\n",
      "id               0\n",
      "content          0\n",
      "username         0\n",
      "like_count       1\n",
      "retweet_count    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "date              object\n",
      "id                object\n",
      "content           object\n",
      "username          object\n",
      "like_count       float64\n",
      "retweet_count    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics:\n",
      "        like_count  retweet_count\n",
      "count  1999.000000    1999.000000\n",
      "mean      4.855428       1.061531\n",
      "std      44.746283       9.308887\n",
      "min       0.000000       0.000000\n",
      "25%       0.000000       0.000000\n",
      "50%       1.000000       0.000000\n",
      "75%       2.000000       0.000000\n",
      "max    1550.000000     259.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265567    [OpenAI, says, it, â€™, s, already, partnered, w...\n",
      "323606    [I, gave, chat, gpt, access, to, my, hinge, pr...\n",
      "77999     [Embrace, the, power, of, AI, in, the, classro...\n",
      "105848    [Returning, to, Twitter, to, see, what, people...\n",
      "288574    [Do, n't, let, fear, hold, you, back, from, re...\n",
      "                                ...                        \n",
      "147568    [Conversation, with, my, 11, yr, old, :, do, y...\n",
      "204194    [Could, you, train, a, ChatGPT-beating, model,...\n",
      "1613      [#, GPT4, is, here, already, (, #, ChatGPT, is...\n",
      "322582    [@, dreamwieber, Now, You, can, create, a, vir...\n",
      "190609    [Discover, a, mind-bending, journey, through, ...\n",
      "Name: content_tokenized, Length: 1999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text data in the \"content\" column\n",
    "df['content_tokenized'] = df['content'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "\n",
    "# Display the tokenized data\n",
    "print(df['content_tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/maxwelllondon/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/maxwelllondon/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/maxwelllondon/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265567    [[(OpenAI, NNP)], (says, VBZ), (it, PRP), (â€™, ...\n",
      "323606    [(I, PRP), (gave, VBD), (chat, WP), (gpt, JJ),...\n",
      "77999     [(Embrace, NN), (the, DT), (power, NN), (of, I...\n",
      "105848    [(Returning, VBG), (to, TO), [(Twitter, NNP)],...\n",
      "288574    [(Do, VBP), (n't, RB), (let, VB), (fear, VB), ...\n",
      "                                ...                        \n",
      "147568    [(Conversation, NN), (with, IN), (my, PRP$), (...\n",
      "204194    [(Could, MD), (you, PRP), (train, VB), (a, DT)...\n",
      "1613      [(#, #), [(GPT4, NNP)], (is, VBZ), (here, RB),...\n",
      "322582    [(@, JJ), (dreamwieber, NN), (Now, RB), (You, ...\n",
      "190609    [(Discover, VB), (a, DT), (mind-bending, JJ), ...\n",
      "Name: ner_result, Length: 1999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def perform_ner(tokenized_text):\n",
    "    tagged_text = nltk.pos_tag(tokenized_text)  # Perform part-of-speech tagging\n",
    "    ner_result = ne_chunk(tagged_text)  # Perform named entity recognition\n",
    "    return ner_result\n",
    "\n",
    "# Apply NER to the 'content_tokenized' column\n",
    "df['ner_result'] = df['content_tokenized'].apply(perform_ner)\n",
    "\n",
    "# Display the named entity recognition results\n",
    "print(df['ner_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 701\n",
      "OpenAI 127\n",
      "Chat GPT 93\n",
      "AI 89\n",
      "GPT 89\n",
      "Microsoft 82\n",
      "Google 61\n",
      "GPT4 45\n",
      "Bard 29\n",
      "NFT 18\n",
      "chatGPT 18\n",
      "YouTube 18\n",
      "SEO 12\n",
      "GenerativeAI 11\n",
      "NLP 11\n",
      "LLM 11\n",
      "Python 11\n",
      "Great 10\n",
      "API 9\n",
      "ChatGpt 9\n",
      "Twitter 8\n",
      "Midjourney 8\n",
      "China 8\n",
      "New 8\n",
      "IoT 8\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.tree import Tree\n",
    "\n",
    "# Flatten the named entity results and extract named entities\n",
    "flattened_entities = []\n",
    "for sublist in df['ner_result']:\n",
    "    for ent in sublist:\n",
    "        if isinstance(ent, Tree):\n",
    "            flattened_entities.append(' '.join([token[0] for token in ent.leaves()]))\n",
    "\n",
    "# Count the frequency of named entities\n",
    "entity_counts = Counter(flattened_entities)\n",
    "\n",
    "# Get the top 25 named entities\n",
    "top_entities = entity_counts.most_common(25)\n",
    "\n",
    "# Display the top 25 named entities\n",
    "for entity, count in top_entities:\n",
    "    print(entity, count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
